{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3482f58f-bece-4a5e-a9b9-090c39d2c278",
   "metadata": {},
   "source": [
    "# How to install your own Llama server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a1276-2584-46c2-9b36-ad1108defbfc",
   "metadata": {},
   "source": [
    "### Installation of a local Llama server\n",
    "\n",
    "This notebook explains how to install a llama server locally. The smallest Llama3 model (8B parameters) is almost 5GB in size. You need sufficient memory to load this model.\n",
    "\n",
    "* open a terminal, install a new venv and activate it:\n",
    "    * python -m venv venv\n",
    "    * source venv/bin/activate\n",
    "\n",
    "* install the following dependencies within the virtual environment:\n",
    "    * pip install --upgrade --quiet llama-cpp-python \n",
    "    * pip install sse_starlette \n",
    "    * pip install starlette_context \n",
    "    * pip install pydantic_settings \n",
    "\n",
    "* Download a Llama model from [huggingface](https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF) and place it in a local folder. You can also download the model from the next [Google-drive](https://drive.google.com/file/d/1gIYCP-3zCjVlD8EXm5OggKXaYH4MLqTB/view?usp=share_link).\n",
    "\n",
    "To launch llama_server specify the path to the local model and the port:\n",
    "\n",
    "    * python -m llama_cpp.server --host 0.0.0.0 --model ./models/Meta-Llama-3-8B-Instruct.Q2_K.gguf --n_ctx 2048 --port 9001\n",
    "\n",
    "If there are no error messages, the server is up and running and you can make calls to this port 9001 using a Llama client using: http://localhost:9001/v1. See the notebook **llama-chat.ipynb** how to run a chatbot that uses this server.\n",
    "\n",
    "If you do not have sufficient memory or get an error message launching the server, please get in touch with the CLTL server. On request, we can provide you with access to our CLTL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6120a-c1e3-47e9-9220-8bf4ce6044e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
