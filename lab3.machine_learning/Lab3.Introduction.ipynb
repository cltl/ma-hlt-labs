{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "RMA/Text Mining MA, Introduction to HLT\n",
    "\n",
    "In Lab3, we are going to introduce machine learning. Lab3 contains the following notebooks:\n",
    "\n",
    "<ol>\n",
    "    <li>Lab3.1.ml.basics.ipynb\n",
    "    <li>Lab3.2.ml.evaluation.ipynb\n",
    "    <li>Lab3.3.ml.sentiment-analysis-with-sklearn.ipynb\n",
    "    <li>Lab3.4.ml.emotion-detection-bow.ipynb\n",
    "    <li>Lab3.5.interannotator_agreement.ipynb</li>\n",
    "</ol>\n",
    "\n",
    "Lab3.1 and Lab3.2 explain the basics of machine learning and introduce the machine learning package *sklearn*. In Lab3.1, you build a classifier with some toy data. In Lab3.2, we explain the basics for evaluating a system using *sklearn* functions.\n",
    "\n",
    "## Sentiment in text\n",
    "In Lab3.3, we explain how you can  assign sentiment to tweets by training a classifier from positive and negative tweets, as well as from positive and negative movie reviews.\n",
    "\n",
    "## Emotion in text\n",
    "In Lab3.4 we do the same but with emotion labels to texts. Emotions are more complex than sentiment and more difficult to detect. We will use a classical set of 6 basic emotions and we are going to look at a data set that is derived from the series *Friends* and some more Twitter data that was annotated with emotion labels.\n",
    "\n",
    "## Data quality\n",
    "We compare systems usually against human performances or interpretations. For this people need to label texts. But people also make mistakes, which is why we need to determine the Inter-Annotator-Agreement or IAA for a data set. In Lab3.5 we show how this can be done using an NLTK metric function. The IAA score tells you how well people can do this task in comparison to labelling data randomly. The performance of people is often considered the upper ceiling for machines. If a machine is said to outperform people, it usually means that machine performance is measured against labeled data that has been adjudicated by resolving any disagreements among people.\n",
    "\n",
    "Lab3.4 and the Lab3.Assignment are essential for the final assignment of this course. Make sure you can run these notebooks yourself (without the group) and know how to build and test an emotion classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
