{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the assignment for Lab 1. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise. However, these points are just an indication of what parts we value more. The assignment itself is assessed as PASS/NO-PASS. \n",
    "\n",
    "In general, we value a critical analysis of the OUTPUT of running code more than just showing that you can run the code (running notebook cells). So if you succesfully carried out the instructed commands in a notebook you are not done yet. We want you to analyse the output, understand what the code is doing with language and text. Be critical, think about how to explain what you observe and write this down in the notebook after running the code. It will be stated clearly in the assignment when we expect this from you.\n",
    "\n",
    "You can make the assignment as a group but make sure that you understand and can carry out the coding yourself as well. You need these skills for your final assignment that is graded individually. Feedback will be given at the group level.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text stored in the file (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who to contact for questions\n",
    "* Piek Vossen (piek.vossen@vu.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name of the group and the students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group name: [HERE SHOULD BE THE GROUP NAME]\n",
    "\n",
    "Student names: [HERE SHOULD BE THE STUDENT NAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk. It should be located in the same folder as this notebook. The most simple way is to specify the full path to the file, e.g.:\n",
    "\n",
    "```\n",
    "path_to_file='/Users/piek/Desktop/t-ONDERWIJS/2021-2022/t-MA-HLT-introduction-2021/ma-hlt-labs/lab1.toolkits'\n",
    "```\n",
    "\n",
    "This may work for me but not for you as it is unlikely that the file has the same path on your machine.\n",
    "\n",
    "You can locate the file on your disk and adapt the path to the file manually. Note that Windows uses backward slashes while Mac and Linux use forward slashes in the path.\n",
    "\n",
    "A more advanced method is to use the Path module to find the directory of this notebook. Once we have that, we only need to concatenate the name of the text file to this path. This is how you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory of this notebook: /Users/piek/Desktop/t-MA-HLT-introduction-2024/ma-hlt-labs/lab1.toolkits\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "print('Current directory of this notebook:', cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the text file: /Users/piek/Desktop/t-MA-HLT-introduction-2024/ma-hlt-labs/lab1.toolkits/Lab1-apple-samsung-example.txt\n"
     ]
    }
   ],
   "source": [
    "## We can now stick the name of the file to the end of the Path using the *joinpath* function:\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print('Path to the text file:', path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure whether the path is correct, you can check if the file exist in that location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above says: **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook. In Jupyter lab you should see it in the file overview panel to the left next to the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open the file and access its content. Lets read the complete content and ask for it length using the 'len' function, which will tell us how many characters a string has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices. Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created a string object with the name 'text' that we can use for the assignment below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for some reason, you see weird characters in the text you may have a problem with the character encoding. Computers use different systems to represent scripts. For most languages UTF-8 will work as it has representations for many different characters. In some cases, especially older texts, Latin encodings have been used which works for English and some languages but cannot represent characters in others. For non-Western scripts special encodings have been defined. You never know for sure what encoding a text is in but now-adays most texts are in UTF-8.\n",
    "\n",
    "## What to do if you see weird tokens?\n",
    "First check if you are really using Python 3.x and not Python 2.x when running the notebook. You can do this using: \n",
    "\n",
    "    import platform\n",
    "    print(platform.python_version())\n",
    "\n",
    "If your are running 3.x and still have encoding problems try to open the file as utf-8:\n",
    "\n",
    "    with open(path_to_file, encoding=‘utf-8') as infile:\n",
    "    \n",
    "Note that when you open a text file in a plain text editor, you never know how it loads the file. The weird characters may still be there or disappear. In some cases, you can try to save the text file again using UTF-8 but this can also corrupt your file. It is wise to make a copy of the file before you try this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 3] Exercise 1: NLTK\n",
    "Extract a list of all the named entity expressions from the complete text using NLTK.\n",
    "Note that you do not need to split the text into sentences but you can apply your functions to the text as a whole.\n",
    "\n",
    "Your result should be a list with only the named entity expressions with their type. \n",
    "For example:\n",
    "\n",
    "```[(ORGANIZATION San/NNP Jose/NNP), (GPE California/NNP)]```\n",
    "\n",
    "You need to iterate through the results and store the entities in a result list while skipping anything that is not a named entity expression.\n",
    "\n",
    "*TIP*: Remember that the entities of the ne_chunker are of the type *nltk.tree.tree.Tree* so you may test ```if type(element)==nltk.tree.tree.Tree``` to keep it in your result list and otherwise to ignore it:\n",
    "\n",
    "```\n",
    "nltk_entities = []\n",
    "for item in list:\n",
    "      if type(item)==nltk.tree.tree.Tree:\n",
    "          nltk_entities.append(item)\n",
    "print(nltk_entities)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[your NLTK code comes here]\n",
    "nltk_entities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 3] Excercise 2: spaCy\n",
    "Process the same text using spaCy and extract a list of all the named entity expression according to spaCy.\n",
    "\n",
    "The output should look as follows:\n",
    "\n",
    "```[('San Jose', 'GPE'), ('California', 'GPE')]```\n",
    "\n",
    "Note that you need to combine the text with the label_ of the entities in a tuple. You can combine elements in a tuple by surrounding them with round brackets, for example ```(ent.text, ent.label_)``` forms a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[your spacy code comes here]\n",
    "spacy_entities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Compare spacy and NLTK\n",
    "\n",
    "Compare the processing of spaCy and NLTK, answering the following questions:\n",
    "    \n",
    "* The number of sentences\n",
    "* The number of tokens\n",
    "* The number of entities per entity type\n",
    "\n",
    "Discuss the quality of the entities for each type. Which is better NLTK or spaCY? Any idea why? Which mistakes are made by both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [ here comes the code to count the sentences, tokens and entities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Here comes your discussion about the quality of the NERC output of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
