{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB2: Word meaning, similarity and relatedness\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobody can tell how many words there are in a language nor what different meanings these words have or can have in different contexts. Nobody knows how to define these meanings correctly either. \n",
    "\n",
    "**WordNet** is a semantic lexical database that can be seen as a proxy for the words of the English languages with their meanings defined through lexical semantic relations. The core unit of WordNet is the synset: a set of synonymous words that represent a single concept. For example, teh English words *car, auto, automobile, machine, motorcar* form a synset in the English WordNet. Lexical semantic relations are defined between synsets. Likewise the car synset is related to the synset *motor vehicle, automotive vehicle* through the hyponymy relation. As WordNet contain over a hundred thousands words and synsets, it forms a huge network of concepts and a mapping of the English vocabulary to these concepts. \n",
    "\n",
    "Wordnets have also been built for many other languages as well, mostly by *translating* the synsets from English to this language and copying the meanings over (the so-called expand method). Wordnets can be used to calculate the similarity of word pairs through different techniques. You are going to explore these techniques in this notebook.\n",
    "\n",
    "**Word embeddings** are vector representations for words derived from large volumes of text through unsupervised machine learning. These vector representations tyically have a few hundred dimensions. Each word has different values for these dimensions but similar words have similar values. The values are learned by predicting the context words observed in the large text collection. A neural network with one hidden layer adapts the weights to predict the correct context words and not the incorrect context words. After training, the weights of the hidden layer form the dense vector. Since semantically related words occur in similar contexts, the weights are also similar. \n",
    "\n",
    "Word embeddings are a powerful resource that can be learned without supervision from text. Whereas wordnets have been built manually on the basis of human intuition, embeddings are derived empirically. It is still to be seen what yields better results: human intuition or sampling of empirical data.\n",
    "\n",
    "In this LAB, you are going to work with:\n",
    "\n",
    "* Wordnet in English and other languages, as provided in NLTK\n",
    "* Embeddings built from Wikipedia for different languages\n",
    "* Create you own embeddings from text corpora provided by the Leibnitz Corpora Collection for some language\n",
    "* Compare wordnet and embeddings in terms of similarity and relatedness\n",
    "\n",
    "LAB2 contains 5 notebooks, excluding this introduction:\n",
    "\n",
    "* Lab2.1.NLTK_wordnet.ipynb\n",
    "* Lab2.2.NLTK.Wikipedia2Vec.ipynb\n",
    "* Lab2.3.create_embeddings_in_some_language.ipynb\n",
    "* Lab2.4.Assignment.ipynb\n",
    "* Lab2.5.NLTK_concordances.ipynb\n",
    "* Lab2.6.NLTK_framenet.ipynb\n",
    "\n",
    "You are supposed to work through these notebooks in this order before making the assignment. The final two notebooks are not necessary for the assignment but nice to see what text-corpus functions are provided in NLTK and that you can call FrameNet as well to semantically label texts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
