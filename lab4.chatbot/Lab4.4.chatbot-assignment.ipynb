{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 about NERC (Max 20 points of your final grade)\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "RMA/Text Mining MA, Introduction to HLT\n",
    "\n",
    "This notebook describes Assignment-3 of the Human Language Technology course. \n",
    "\n",
    "\n",
    "**Learning goals**\n",
    "* going from linguistic input format to representing it in a feature space\n",
    "* working with pretrained word embeddings\n",
    "* train a supervised classifier (SVM)\n",
    "* evaluate a supervised classifier (SVM)\n",
    "\n",
    "We assume you have worked through the following notebook:\n",
    "* **Lab3.1.ml.basics.ipynb**\n",
    "* **Lab3.2.ml.linguistic_features.ipynb**\n",
    "* **Lab3.3.ml.embeddings.ipynb**\n",
    "* **Lab3.4.ml.evaluation.ipynb**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 2] Exercise 1: terms and definitions\n",
    "* **[0.5points] a) Explain what NER is**\n",
    "* **[0.5points] b) Explain what NERC is**\n",
    "* **[0.5points] c) Explain what the IOB format is and how it represents both the NER and NERC task.**\n",
    "* **[0.5 point] d). Explain what one-hot-encoding is.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 18] Exercise 2: Training and evaluating an SVM using CoNLL-2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1 point] a) Load the CoNLL-2003 training data using the *ConllCorpusReader* and create for both *train.txt* and *test.txt*:**\n",
    "\n",
    "    -a list of dictionaries representing word and PoS features for each training instances, e..g,\n",
    "    ```\n",
    "    [\n",
    "    {'words': 'EU', 'pos': 'NNP'}, \n",
    "    {'words': 'rejects', 'pos': 'VBZ'},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    -the NERC labels associated with each training instance, e.g.,\n",
    "    dictionaries, e.g.,\n",
    "    ```\n",
    "    [\n",
    "    'B-ORG', \n",
    "    'O',\n",
    "    ....\n",
    "    ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "train = ConllCorpusReader('nerc_datasets/CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "       # add features\n",
    "    }\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ConllCorpusReader('nerc_datasets/CONLL2003', 'test.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "\n",
    "test_features = []\n",
    "test_gold_labels = []\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "        # add features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3 point] b) provide descriptive statistics about the training and test data:**\n",
    "* How many instances are in train and test?\n",
    "* Provide a frequency distribution of the NERC labels, i.e., how many times does each NERC label occur?\n",
    "* Discuss to what extent the training and test data is balanced (equal amount of instances for each NERC label) and to what extent the training and test data differ?\n",
    "\n",
    "Tip: you can use the following `Counter` functionality to generate frequency counts from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 2, 3: 1, 5: 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "my_list=[1,2,1,3,2,5]\n",
    "Counter(my_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3 points] d. Concatenate the train and test features (the list of dictionaries) into one list. Load it using the *DictVectorizer*. Afterwards, split it back to training and test.**\n",
    "\n",
    "Tip: You have to concatenate the train and test data into one data set and next you have to apply the DictVectorizer to the concatenated data.\n",
    "\n",
    "The order of the rows is maintained. You can hence use an index (number of training instances) to split the_array back into train and test, e.g. \n",
    "\n",
    "````\n",
    "train_onehot=concatenated_list[:len(training_instances] ### upto end of training\n",
    "test_onehot=concatenated_list[len(training_instances:]  ### starting from end of training\n",
    "````\n",
    "\n",
    "WARNING(!!!!): Do NOT use `\n",
    "from sklearn.model_selection import train_test_split` here because it will divide the whole data set differently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-457a6076d92a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-457a6076d92a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    the_array = # your code here\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "the_array = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3 points] e. Train the SVM using the train features and labels and evaluate on the test data. Provide a classification report (sklearn.metrics.classification_report).**\n",
    "The train (*lin_clf.fit*) might take a while. On my computer, it took a few minutes, which is acceptable. Training models normally takes much longer. If it takes more than 15 minutes, you can use a subset for training. Describe the results:\n",
    "* Which NERC labels does the classifier perform well on? Why do you think this is the case?\n",
    "* Which NERC labels does the classifier perform poorly on? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-8-03a62207193d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-03a62207193d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    lin_clf.fit( # your code here)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM classifier by providing it with the training data\n",
    "lin_clf.fit( # your code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predictions_on_test = lin_clf.predict( # your code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(# your code goes here)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You description of the results goes here...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3 points] f. Train a model that uses the embeddings of these words as inputs. Test again on the same data as in 2e. Generate a classification report and compare the results with the classifier you built in 2e.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Google word2vec model\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next function is given to apply any embedding mode that is loaded to any data set and return the list of embeddings for the data\n",
    "\n",
    "def get_inputs(data, model):\n",
    "    inputs=[]\n",
    "    for token, pos, ne_label in data.iob_words():\n",
    "        if token in model:\n",
    "            vector=model[token]\n",
    "        else: # if the word does not exist in the embeddings vocabulary, use an all-zeros vector\n",
    "            vector=[0]*300\n",
    "            #print('not in vocabulary:', token)\n",
    "        inputs.append(vector)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the get_inputs function to get the embeddings for the train and the test data\n",
    "\n",
    "training_inputs=get_inputs(#your code here)\n",
    "test_inputs=get_inputs(#your code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the SVM classifier and apply it to the make the predictions for the test data\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "lin_clf.fit(# your code here)\n",
    "embedding_based_test_predictions = lin_clf.predict(#your code here)\n",
    "report = classification_report(# your code here)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results with the previous report on the same data?\n",
    "What happened to precision?\n",
    "What happened to the recall?\n",
    "Can you explain this?\n",
    "What would be a logical next step to improve the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] f. Train a model that uses the embeddings & PoS features of these words as inputs. Test again on the same data and compare the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
