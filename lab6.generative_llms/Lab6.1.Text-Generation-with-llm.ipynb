{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.2 Use generative Language Models as text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of you have used ChatGPT from OpenAI and noticed that it can respond to your input in a very natural way. ChatGPT is build on top of GPT (Generative Pretrained Transformer) which is a model trained to generate text given a preceding input, so-called prompt (Brown et al 2020). It can do this repetitively up to a certain length, likewise generating short stories.\n",
    "\n",
    "Models such as ChatGPT, although having good performance, are by far too large model to work with locally. Therefore in this notebook, we will use smaller open source models such as Llama and Qwen which are publicly available on huggingface.co.\n",
    "\n",
    "### References\n",
    "\n",
    "Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.\n",
    "\n",
    "OpenAI, 2023. GPT-4 Technical Report. arXiv:2303.08774\n",
    "\n",
    "Llama: Touvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière et al. \"Llama: Open and efficient foundation language models.\" arXiv preprint arXiv:2302.13971 (2023). [The Llama 3 Herd of Models](https://scontent-ams2-1.xx.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgEka7Z4&_nc_ht=scontent-ams2-1.xx&oh=00_AYBPnjp-CQn7YnUQU_P-yJATmlaN6oRuEHZ1VrXshBoBwQ&oe=66A6EB8D)\n",
    "\n",
    "Qwen: Bai, Jinze, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan et al. \"Qwen technical report.\" arXiv preprint arXiv:2309.16609 (2023)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative LLMs are trained to respond to prompts. The prompt is given as a list of **dict** strings defining the role of the **system** (the model) and the input given by the **user**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [{\"role\": \"system\", \"content\": \"Generate 10 alternative sentences by completing the next input text.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Bach sat down at his organ and played\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```transformers``` module can also be used to create a pipeline to generate a text as a response to prompt:\n",
    "\n",
    "```# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen3-1.7B-Base\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "response = pipe(messages)\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However it takes a lot of memory and time to download models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the pipeline modules, we will use another package ```ChatOllama``` from **langchain** that was also used for your chat before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model=\"qwen3:1.7b\"\n",
    "\n",
    "chat = ChatOllama(\n",
    "            model=model,\n",
    "            temperature= 0.1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(prompt)\n",
    "\n",
    "### We need to remove the <think></think> part from the output\n",
    "end_of_think = response.content.find(\"</think>\")\n",
    "answer = response\n",
    "if end_of_think>0:\n",
    "    think = response.content[:end_of_think+8]\n",
    "    answer = response.content[end_of_think+8:].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking aloud <think>\n",
      "Okay, the user wants me to generate 10 alternative sentences by completing the sentence \"Bach sat down at his organ and played...\" Let me start by understanding the original sentence. It's about Johann Sebastian Bach playing his organ. The user probably wants different ways to describe the action, maybe varying the verbs or adding details.\n",
      "\n",
      "First, I need to think about different verbs that can replace \"played.\" Words like \"sang,\" \"composed,\" \"rehearsed,\" \"performed,\" \"played,\" \"marched,\" \"swept,\" \"danced,\" \"wrote,\" \"recited,\" \"marched.\" Wait, \"marched\" might not fit here. Maybe \"swept\" or \"danced\" could work. Also, adding adjectives or different structures.\n",
      "\n",
      "Next, think about the context. Bach is known for his organ music, so maybe mention the piece or the effect. For example, \"Bach sat down at his organ and played a sonata.\" Or \"Bach sat down at his organ and played a fugue.\" Also, maybe include the audience or the reaction. \"Bach sat down at his organ and played for the audience.\" Or \"Bach sat down at his organ and played with the audience.\"\n",
      "\n",
      "I need to make sure each sentence is unique and uses different elements. Avoid repetition. Check for grammatical correctness. Let me list possible variations:\n",
      "\n",
      "1. Bach sat down at his organ and played a sonata.\n",
      "2. Bach sat down at his organ and played a fugue.\n",
      "3. Bach sat down at his organ and played a symphony.\n",
      "4. Bach sat down at his organ and played a cantata.\n",
      "5. Bach sat down at his organ and played a prelude.\n",
      "6. Bach sat down at his organ and played a movement.\n",
      "7. Bach sat down at his organ and played a piece.\n",
      "8. Bach sat down at his organ and played a composition.\n",
      "9. Bach sat down at his organ and played a melody.\n",
      "10. Bach sat down at his organ and played a note.\n",
      "\n",
      "Wait, \"played a note\" might be too simple. Maybe \"Bach sat down at his organ and played a note.\" But that's not very descriptive. Maybe \"Bach sat down at his organ and played a note of the scale.\" Or \"Bach sat down at his organ and played a note of the melody.\"\n",
      "\n",
      "Also, consider different verbs: \"swept,\" \"danced,\" \"recited,\" \"marched.\" For example:\n",
      "\n",
      "11. Bach sat down at his organ and swept the audience with his music.\n",
      "12. Bach sat down at his organ and danced with the audience.\n",
      "13. Bach sat down at his organ and recited a poem.\n",
      "14. Bach sat down at his organ and marched through the hall.\n",
      "15. Bach sat down at his organ and played a piece that moved the audience.\n",
      "\n",
      "But the user asked for 10 sentences, so maybe I need to stick to the initial 10. Let me check again. The original sentence is \"Bach sat down at his organ and played...\" So the first part is \"sat down at his organ,\" and the second part is the action. The user wants alternative sentences by completing the next input text. So the structure is \"Bach sat down at his organ and played...\" with different verbs or phrases.\n",
      "\n",
      "I need to make sure each sentence is different. Maybe include different types of music, like \"cantata,\" \"fugue,\" \"sonata,\" \"prelude,\" \"movement,\" \"composition,\" \"melody,\" \"piece,\" \"symphony.\" Also, maybe add adjectives like \"with passion,\" \"in a solemn tone,\" \"for the audience,\" \"as he composed,\" \"while composing.\"\n",
      "\n",
      "So possible sentences:\n",
      "\n",
      "1. Bach sat down at his organ and played a sonata.\n",
      "2. Bach sat down at his organ and played a fugue.\n",
      "3. Bach sat down at his organ and played a symphony.\n",
      "4. Bach sat down at his organ and played a cantata.\n",
      "5. Bach sat down at his organ and played a prelude.\n",
      "6. Bach sat down at his organ and played a movement.\n",
      "7. Bach sat down at his organ and played a piece.\n",
      "8. Bach sat down at his organ and played a composition.\n",
      "9. Bach sat down at his organ and played a melody.\n",
      "10. Bach sat down at his organ and played a note.\n",
      "\n",
      "That's 10. Each is a different type of music piece. Maybe add some variation in the verbs. For example, \"Bach sat down at his organ and played a piece that moved the audience.\" Or \"Bach sat down at his organ and played a piece that filled the hall with music.\" But the user might want more concise sentences. So the first 10 are the ones I listed. I need to make sure they are all valid and distinct.\n",
      "</think>\n",
      "\n",
      "The final answer 1. Bach sat down at his organ and played a sonata.  2. Bach sat down at his organ and played a fugue.  3. Bach sat down at his organ and played a symphony.  4. Bach sat down at his organ and played a cantata.  5. Bach sat down at his organ and played a prelude.  6. Bach sat down at his organ and played a movement.  7. Bach sat down at his organ and played a piece.  8. Bach sat down at his organ and played a composition.  9. Bach sat down at his organ and played a melody.  10. Bach sat down at his organ and played a note.\n"
     ]
    }
   ],
   "source": [
    "print(\"Thinking aloud\", think)\n",
    "print()\n",
    "print(\"The final answer\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we define the client, we can not only adjust the prompt but also the temperature. Temperatures closer to 1.0 make the model become more creative, closer to 1.0 it will follow the instructions more in a strict way. So let's try again with a high temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_creative = ChatOllama(\n",
    "            model=model,\n",
    "            temperature= 0.9,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bach sat down at his organ and played a sonata.  2. Bach sat down at his organ and played a concerto.  3. Bach sat down at his organ and played a cantata.  4. Bach sat down at his organ and played a fugue.  5. Bach sat down at his organ and played a symphony.  6. Bach sat down at his organ and played a chorale.  7. Bach sat down at his organ and played a piece.  8. Bach sat down at his organ and played a melody.  9. Bach sat down at his organ and played a composition.  10. Bach sat down at his organ and played a movement.\n"
     ]
    }
   ],
   "source": [
    "response = chat_creative.invoke(prompt)\n",
    "\n",
    "### We need to remove the <think></think> part from the output\n",
    "end_of_think = response.content.find(\"</think>\")\n",
    "answer = response\n",
    "if end_of_think>0:\n",
    "    think = response.content[:end_of_think+8]\n",
    "    answer = response.content[end_of_think+8:].replace(\"\\n\", \"\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see that it got more expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us set the temperature back to 0.1 and try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Beethoven sat down at his organ and composed a symphony.  2. Beethoven sat down at his organ and played a sonata.  3. Beethoven sat down at his organ and performed a piece.  4. Beethoven sat down at his organ and played a nocturne.  5. Beethoven sat down at his organ and played a fugue.  6. Beethoven sat down at his organ and played a prelude.  7. Beethoven sat down at his organ and played a piece that would later become a classic.  8. Beethoven sat down at his organ and played a piece that marked a new era in classical music.  9. Beethoven sat down at his organ and played a composition that inspired a new generation.  10. Beethoven sat down at his organ and played a melody that would forever change the landscape of classical music.\n"
     ]
    }
   ],
   "source": [
    "prompt = [{\"role\": \"system\", \"content\": \"Generate 10 alternative sentences by completing the next input text.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Beethoven sat down at his organ and played\"}]\n",
    "\n",
    "\n",
    "response = chat.invoke(prompt)\n",
    "\n",
    "### We need to remove the <think></think> part from the output\n",
    "end_of_think = response.content.find(\"</think>\")\n",
    "answer = response\n",
    "if end_of_think>0:\n",
    "    think = response.content[:end_of_think+8]\n",
    "    answer = response.content[end_of_think+8:].replace(\"\\n\", \"\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us switch the language of the input, as Qwen is a multilingual model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Beethoven ging achter zijn orgel zitten en speelde een lied dat hij had opgesteld.  2. Beethoven ging achter zijn orgel zitten en speelde een symfonie dat hij had opgesteld.  3. Beethoven ging achter zijn orgel zitten en speelde een konzert dat hij had opgesteld.  4. Beethoven ging achter zijn orgel zitten en speelde een motief dat hij had opgesteld.  5. Beethoven ging achter zijn orgel zitten en speelde een klok dat hij had opgesteld.  6. Beethoven ging achter zijn orgel zitten en speelde een opname dat hij had opgesteld.  7. Beethoven ging achter zijn orgel zitten en speelde een kantoor dat hij had opgesteld.  8. Beethoven ging achter zijn orgel zitten en speelde een kantoor dat hij had opgesteld.  9. Beethoven ging achter zijn orgel zitten en speelde een kantoor dat hij had opgesteld.  10. Beethoven ging achter zijn orgel zitten en speelde een kantoor dat hij had opgesteld.\n"
     ]
    }
   ],
   "source": [
    "prompt = [{\"role\": \"system\", \"content\": \"Generate 10 alternative sentences by completing the next input text in Dutch.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Beethoven ging achter zijn orgel zitten en speelde\"}]\n",
    "\n",
    "\n",
    "response = chat.invoke(prompt)\n",
    "\n",
    "### We need to remove the <think></think> part from the output\n",
    "end_of_think = response.content.find(\"</think>\")\n",
    "answer = response\n",
    "if end_of_think>0:\n",
    "    think = response.content[:end_of_think+8]\n",
    "    answer = response.content[end_of_think+8:].replace(\"\\n\", \"\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions in English, completions as Dutch. You can also give the instructions in Dutch if you want or try other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [{\"role\": \"system\", \"content\": \"Genereer 10 alternatieve zinnen door de volgende tekst af te maken.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Beethoven ging achter zijn orgel zitten en speelde\"}]\n",
    "\n",
    "response = chat.invoke(prompt)\n",
    "\n",
    "### We need to remove the <think></think> part from the output\n",
    "end_of_think = response.content.find(\"</think>\")\n",
    "answer = response\n",
    "if end_of_think>0:\n",
    "    think = response.content[:end_of_think+8]\n",
    "    answer = response.content[end_of_think+8:].replace(\"\\n\", \"\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Dutch instructions do make a big difference as the quality went down drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
