{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "RMA/Text Mining MA, Introduction to HLT\n",
    "\n",
    "In Lab3, we are going to introduce machine learning. Lab3 contains the following notebooks:\n",
    "\n",
    "<ol>\n",
    "    <li>Lab3.1.ml.basics.ipynb\n",
    "    <li>Lab3.2.ml.evaluation.ipynb\n",
    "    <li>Lab3.3.rules.sentiment-analysis-with-VADER.ipynb\n",
    "    <li>Lab3.4.ml.sentiment-analysis-with-sklearn.ipynb\n",
    "    <li>Lab3.5.ml.emotion-detection-bow.ipynb\n",
    "    <li>Lab3.6.ml.emotion-detection-word-embeddings.ipynb\n",
    "    <li>Lab3.7.ml.emotion-detection-on-tweets.ipynb\n",
    "    <li>Lab3.8.ml.nerc-linguistic-features.ipynb\n",
    "    <li>Lab3.9.ml.nerc-word-embeddings.ipynb\n",
    "    <li>Lab3.10.ml.nerc.assignment.ipynb\n",
    "</ol>\n",
    "\n",
    "Lab3.1 and Lab3.2 explain the basics of machine learning and introduce the machine learning package *sklearn*. In Lab3.1, you build a classifier with some toy data. In Lab3.2, we explain the basics for evaluating a system using *sklearn* functions.\n",
    "\n",
    "In Lab3.3, we introduce the VADER module that is included in NLTK. VADER is rule based and uses a lexicon with sentiment scores assigned by the crowd for tweets. Next in Lab3.4, we explain how you can also assign sentiment to tweets by training a classifier from positive and negative tweets, as well as from positive and negative movie reviews.\n",
    "\n",
    "Lab3.5, 3.6 and 3.7 deal with assigning emotion labels to texts. Emotions are more complex than sentiment and more difficult to detect. We will use a standrard set of 6 basic emotion and we are going to look at a data set that is derived from the series *Friends*. We train an emotion classifier that uses a Bag-of-Words representation of text (Lab3.5) and another classifier that uses word-embeddings instead (Lab3.6). In Lab3.7, we check what happens if we apply these classifiers to tweets that have been annotated with emotions instead of conversations in *Friends* (on which they were trained).\n",
    "\n",
    "Lab3.5, 3.6 and 3.7 are important for the Chatbot assignment of this course. Make sure you can run these notebooks yourself and know how to build and test an emotion classifier.\n",
    "\n",
    "Lab3.8, 3.9 and 3.10 are extra notebooks that demonstrate how a Named-Entity-Recognition-and-Classification (NERC) system can be trained using many different features represented in the so-called CoNLL IOB (Inside-Outside-Beginning) notation. These classifiers are different because they operate at the token level. Each token is assigned a tag to indicate if it is part of a named entity expression or not. As such, NERC is seen as a sequence tagging tasks. We look into one-hot-vector representations for tokens versus word-embedding representations. Lab3.10 is the NERC assignment of this course.\n",
    "\n",
    "In the course, students either do the Chatbor assignment or the NERC assignment. The Chatbot assignment is explained in Lab4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
