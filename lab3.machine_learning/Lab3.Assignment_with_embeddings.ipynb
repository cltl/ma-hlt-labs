{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 Assignment: Training and Testing classifiers on a data set with tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build and apply classifiers using a data set with emotion labels from the 2017 *Wassa* workshop:\n",
    "\n",
    "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
    "\n",
    "### Reference\n",
    "   Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.\n",
    "\n",
    "The texts are tweets and therefore a different genre than the spoken utterances from the conversations in the MELD data set. The data set is included in the distribution of this lab, where we aggregated all the training and test data in a single file. The notebook already includes the code for loading the CSV files in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the tweet data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              Tweet  Label  Score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...  anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...  anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...  anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...  anger  0.896"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = './data/wassa/training/all.train.tsv'\n",
    "dftweets_train = pd.read_csv(filepath, sep='\\t')\n",
    "dftweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3613 entries, 0 to 3612\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      3613 non-null   int64  \n",
      " 1   Tweet   3613 non-null   object \n",
      " 2   Label   3613 non-null   object \n",
      " 3   Score   3613 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 113.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dftweets_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### Test data\n",
    "filepath = './data/wassa/testing/all.test.tsv'\n",
    "dftweets_test = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Analysing the data [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE A BAR CHART FOR THE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE A BAR CHART FOR THE TEST DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE COME YOUR COMMENTS ON THE DISTRIBUTION OF THE TRAIN AND TEST DATA AND A COMPARISON WITH THE DISTRIBUTION IN MELD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Extracting the texts and labels for the training and testing [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO EXTRACT THE TRAINING TEXTS AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO EXTRACT THE TEST TEXTS AND LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same functions that we used in the notebook *Lab3.6.ml.emotion-detection.embeddings.ipynb* to get averaged embeddings for the tweets. \n",
    "In order to use exactly the same function and to be able to re-use them again, we copied these functions to a separate python file \"lab3_util.py\". You can open the file in Jupyter to inspect its content.\n",
    "\n",
    "We can now import this file as we do with other packages and apply it in this notebook but also in other code. This keeps our notebook readable and compact and makes sure we always use the same functions and do not accidently change them across notebooks.\n",
    "\n",
    "For future coding, it is wise to also apply this to your own code. Put reusable code as functions in a separate Python file with an appropriate name and import this in different notebooks or other Python files. In this way, you develop your own tools over time and reuse them when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the Python file *lab3_util.py* in this notebook so that the functions are loaded in working memory. The file should be located in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab3_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point onwards, you can call the functions from this file as follows:\n",
    "\n",
    "* util.getAvgFeatureVecs(.....)\n",
    "* util.getMostFrequentWords(.....)\n",
    "\n",
    "Check the parameters of the functions required to call them and check the return values to catch what they return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO DERIVE AVERAGED WORD EMBEDDING REPRESENTATIONS FOR THE TRAINING & TEST DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we check which words are not in the embedding model's vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating and testing a bag-of-words SVM classifier for the Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Representing the tweets as BoW vectors [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO CREATE A BOW REPRESENTATION WITH TF-IDF WEIGHTS FOR THE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REPRESENT THE TEST DATA ACCORDING TO MELD BOW VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Training and testing the BOW SVM Classifier [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO TRAIN AN SVM CLASSIFIER WITH THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO APPLY THE CLASSIFIER TO THE TWEET TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE A CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.3 Analyse the test results [1 point]\n",
    "\n",
    "HERE COMES YOUR ANALYSIS OF THE RESULT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Comparison of the results [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE THE RESULTS WITH THE SVM CLASSIFIER BUILT FROM THE MELD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of The assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
