{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab5 Final assignment: putting all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final assignment is an individual assignment in which you put things together. You can earn 10 points when you carry out the basic tasks and discuss the results poperly, excluding the bonus points. You can earn maximum of 2 bonus points to boost your overall grade for the course. Note that the maximum grade is 10 so ytou cannot add bonus points beyond a 10.\n",
    "\n",
    "   1. **Create and annotate a conversation** [1 POINT]\n",
    "       1. [OPTIONAL] You may adapt the **eliza_language.py** to get better Eliza responses that trigger Ekman emotions \n",
    "       2. create an emotional conversation between a **fake** human and your version of Eliza consisting of 50 human input prompts (a total of 100 turn ids including the prompts from Eliza): use **eliza-chat.ipynb**.\n",
    "       3. annotate your conversation with Ekman emotions as gold labels and save the result to disk as a CSV: use **eliza-chat.ipynb**.\n",
    "   2. **Create a separate notebook Lab5.meld-tweet-bow-svm-emotion-classifier.ipynb to train a BoW SVM Ekman emotion classifier combining all MELD and Tweet data** [3 POINTS]\n",
    "       1. Load the train, test and development data from MELD and WASSA\n",
    "       2. Discuss the statistics on the training data for the Ekman emotions\n",
    "       3. Create a BoW vector representation and train an SVM classifier\n",
    "       4. Save the classifier to disk\n",
    "   2. **Classify the turns with emotion classifiers** [1 POINT]\n",
    "       1. load the annotated conversation from disk in this notebook as a Pandas dataframe\n",
    "       2. Apply the following emotion classifiers to your conversation:\n",
    "           1. BoW SVM classifier trained on the data from MELD and Wassa Tweets (see 2. above)\n",
    "           2. BERT finetuned with GO_emotions, where GO emotions are mapped to Ekman emotions (given in this notebook as shown below)\n",
    "   3. **Evaluate the classifiers against your gold annotations** [1 POINT]\n",
    "       1. Create a classification report and confusion matrix. Only evaluate the human input and ignore the Eliza prompts!\n",
    "       2. Discuss the result:\n",
    "           1. report on performance similarities and differences, \n",
    "           2. formulate what you expected from each model in terms of recall and precision and whether this is confirmed or falsified by the results \n",
    "           3. try to explain what did NOT meet your expectations\n",
    "   4. **[2 BONUS POINT] Classify the conversation with sentiment classifiers**: \n",
    "        1. Define a mapping from Ekman labels to sentiment labels and convert your Ekman gold labels to sentiment values\n",
    "        2. Apply VADER to each utterance and evaluate against the gold sentiment labels of the human responses\n",
    "        3. Evaluate the GO sentiment labels against the gold sentiment labels of the human responses\n",
    "        4. Map the Ekman labels of the BoW-SVM Ekman classifier to sentiment labels and evaluate against the gold sentiment labels for the human responses\n",
    "        5. Train a new BoW-SVM classifier using the MELD and Tweet data after first converting all the Ekman labels to sentiment labels. Save this classifier to disk. A separate notebook is provided for this : **lab5.meld-tweet-bow-svm-sentiment-classifier.ipynb**\n",
    "        6. Load and apply the BoW-SVM sentiment classifier to the conversation and evaluate against the gold sentiment labels for the human responses\n",
    "   5. **Formulate what could be done to improve the automatic classification** [1 POINT]\n",
    "       1. How can you improve the classifiers by:\n",
    "           1. different training data, \n",
    "           2. processing the training data differently\n",
    "       2. Reflect on using different emotion labels: sentiment (in case of the BONUS), Ekman or Go.\n",
    "\n",
    "To be able to run the experiment, you need to have an emotional conversation with Eliza using the notebook **eliza_chat.ipynb** with 50 human turns as input (after 50 prompts from Eliza), annotate this conversation with the Ekman emotion labels and save it to disk. Try to make it a **fake** but emotional conversation, so basicaly an emotional roller coaster exhibiting many different emotions to properly test the classifiers. You can optionally adapt Eliza's responses to better evoke Ekman emotions.\n",
    "\n",
    "Below, we show how you can apply the BERT classifier finetuned with GO emotions to the loaded conversation and add the result to the pandas dataframe. You can simply apply this to your own conversation as is shown here. We also show how the GO emotions are mapped to Ekman emotions and sentiment values. Finally, we show how you can add the GO classifications to the Pandas dataframe of your conversation. This is an example how you can also proceed to you get the results from the other classifiers.\n",
    "\n",
    "If for some reason, you are not able to load the BERT-GO transformer model in your computer and cannot run it do the following:\n",
    "\n",
    "   1. Send me your conversation with the annotations saved in CSV\n",
    "   2. I will apply the transformer model for you and send back the CSV with the GO annotations\n",
    "   3. Load the CSV with the GO anotations and proceed from there\n",
    "\n",
    "After applying the BERT-GO classifier to your conversation, you will also apply a Bag-of-Word SVM classifier to your conversation. For this, you should build a BoW SVM classfier in a separate notebook (**lab5.meld-tweet-bow-svm-emotion-classifier.ipynb**) which combines the MELD and Tweet data into a single set of training data. Note that you can also include the test and development data for training since we are applying the model to your conversation and not to the MELD and Wassa tests. Provide a statistical analysis of all the training data and save the classifier to disk so that you can use it here in this notebook. The notebook **lab5.meld-tweet-bow-svm-emotion-classifier.ipynb** can be used as a guide for building the classifier. Load the BoW SVM classifier that you built in this notebook from disk and apply it to the conversation. Add the result to the Pandas dataframe of the conversation as well. Once the pandas frame is complete with the annotations from all the classifiers, make sure you save it to disk to not loose anything!!!!\n",
    "\n",
    "For the evaluation of the classifiers, you need to extract the gold labels and the classifier labels for each classifcation model separately. When extracting the gold and system labels for the test, you should **ONLY(!!)** use the labels for the human responses and skip Eliza's responses. We provided a function in **lab5_util.py** to do this. \n",
    "\n",
    "Once you have extracted the gold labels and the system labels for the human responses (check if they have the same length and are in the right order), you can do the evaluation. With the **sklearn** functions you can generate a classification report and a confusion matrix (you can use **seaborn** to make the image nicer).\n",
    "\n",
    "You can earn **2 bonus points** by doing an additional sentiment level classification of the conversation. For this you should apply VADER to the conversation, use the BERT GO sentiment mapping or map the BoW SVM Ekman predictions to sentiments. For the latter, you need to make a mapping from Ekman labels to sentiment labels similar to the GO to sentiment mapping in **lab5_util.py**. When you have a mapping of Ekman labels to sentiment values, you can also apply this to the MELD+Tweets training data and create a new BoW-SVM classifier for assigning sentiment values directly. We provided the notebook **lab5.meld-tweet-bow-svm-sentiment-classifier.ipynb** as a way to create this classifier. Save it to disk and apply it to the conversation after loading it from disk. Make sure you add all sentiment classifications and mappings to the Pandas dataframe of the conversation and save this to disk.\n",
    "\n",
    "The evaluation of the sentiment classification should be done in a similar way as for the Ekman emotion classifications: extract the gold sentiment labels and system sentiment labels for the human responses only and generate the classification report and confusion matrix.\n",
    "\n",
    "When you report the results, it makes sense to combine these in a single table. So instead of having separate classification report tables, try to combine these in a single table so that you can easly compare them, as is shown in the following examples. Obviously, the confusion matrixes cannot be combined. You can add these to the appendix of the report on a single page for comparison.\n",
    "\n",
    "## Overview of EKMAN results\n",
    "\n",
    "![Ekman classification of human responses in a conversation](ekman-results.png)\n",
    "\n",
    "## Overview of Sentiment results\n",
    "\n",
    "![Sentiment classification of human responses in a conversation](sentiment-results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment should be submitted individually on CANVAS as a zip file and include the following:\n",
    "\n",
    "   1. OPTIONAL: the **eliza_language.py** if you adapted Eliza \n",
    "   2. The notebook to create a BoW-SVM combining MELD and Tweets for Ekman classification: **lab5.meld-tweet-bow-svm-emotion-classifier.ipynb**\n",
    "   3. The current notebook **lab5.final_assignment.ipynb**\n",
    "   4. OPTIONAL: The notebook to create the BoW-SVM combining MELD and Tweets for sentiment classification: **lab5.meld-tweet-bow-svm-sentiment-classifier.ipynb** \n",
    "   5. A CSV file containing the conversation with all the gold and classifier outputs (use clear column names)\n",
    "   6. A PDF report of max 5 pages without sentiment classification and 8 pages with sentiment classification:\n",
    "       1. Section 1: what you have done and why: be explicit about changes you made e.g. to Eliza or training on MELD+Tweets\n",
    "       2. Section 2: report on the Ekman classification results. Use a single table for recall, precision and f-score and put confusion matrixes in the appendix.\n",
    "       3. OPTIONAL: Section 3 report on the Sentiment results. Use a single table for recall, precision and f-score and put confusion matrixes in the appendix.\n",
    "       4. Section 3 or 4: have a discussion on the results and how to improve the classifiers\n",
    "\n",
    "Use the notebooks that are given as a guide with the code and the output. You should NOT discuss the results in the notebooks but in the report. Use the notebooks to run the experiments and get the results. Include the tables and figures in the report.\n",
    "\n",
    "If any of 2,3,5,6 is missing in the zip file, your submission is not graded. Note that 1., 4. and 6.3 are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loading the conversation saved on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the notebook **eliza-chat.ipynb**, you should create a conversation with Eliza, annotate the conversation with Ekman labels and save it to disk as a CSV file. You should load the saved CSV file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold  \n",
       "0        1  neutral  \n",
       "1        1  sadness  \n",
       "2        1  neutral  \n",
       "3        1  sadness  \n",
       "4        1  neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'my_emotional_conversation.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab5_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CODE TO GET THE TEST TEXTS AND LABELS\n",
    "test_instances =df['utterance']\n",
    "test_labels = df['Gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 10\n"
     ]
    }
   ],
   "source": [
    "# THE CODE TO LIMIT THE TEST LABELS TO THE HUMAN TEST LABELS\n",
    "human_test_labels = util.remove_eliza_labels(df, test_labels)\n",
    "print(len(test_labels), len(human_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. BERT Finetuned for emotion detection with GO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the language model BERT that is finetuned for emotion detection using the *go_emotions* data set. Go_emotions has 28 nuanced emotion labels including neutral, so many more than the basic Ekman emotion that we have seen before. \n",
    "\n",
    "We will define a *sentiment-analysis* pipeline and load the BERT model that was finetuned to classify sentences with the 28 GO_EMOTION labels. It will return a score for all the labels when we set the parameter *return_all_scores* to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE BERT-BASE-GO-EMOTION transformer model and create a pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\" \n",
    "emotion_pipeline = pipeline('sentiment-analysis', \n",
    "                    model=model_name, return_all_scores=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instance *emotion* of a transformer pipeline in analogy of an sentiment analysis classification task that we can apply to any utterance. The pipeline will use the tokenizer of the finetuned model and feed the sentence representation to the classifier as a sequence of contextualized token representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Applying emotion classification to Eliza conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, you will apply the GO_EMOTION classifier *emotion* to the conversation loaded in a Pandas frame. You will also map the GO_EMOTIONS to the 6 basic Ekman emotion and to neutral as well as to sentiment values. For the mappings, we defined a few simple utility functions in **lab5_util.py** . We also define a sort function to list the emotions from the highest score down. You first need to import these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "\n",
    "go_sentiment_emotions = []\n",
    "go_sentiment_scores = []\n",
    "go_ekman_emotions = []\n",
    "go_ekman_scores = []\n",
    "go_emotions = []\n",
    "go_scores = []\n",
    "\n",
    "for index, utterance in enumerate(df['utterance']):\n",
    "    emotion_labels = emotion_pipeline(utterance)\n",
    "    sorted_emotion_labels = util.sort_predictions(emotion_labels[0])\n",
    "    go_emotions.append(sorted_emotion_labels[0]['label'])\n",
    "    go_scores.append(sorted_emotion_labels[0]['score'])\n",
    "\n",
    "    ekman_labels = util.get_averaged_mapped_scores_by_threshold(util.ekman_map, emotion_labels, threshold)\n",
    "    if ekman_labels:\n",
    "        go_ekman_emotions.append(ekman_labels[0]['label'])\n",
    "        go_ekman_scores.append(ekman_labels[0]['score'])\n",
    "    else:\n",
    "        #### none of the labels scored above the threshold\n",
    "        go_ekman_emotions.append('None')\n",
    "        go_ekman_scores.append(0)\n",
    "        \n",
    "\n",
    "    sentiment_labels = util.get_averaged_mapped_scores_by_threshold(util.sentiment_map, emotion_labels, threshold)\n",
    "    if sentiment_labels:\n",
    "        go_sentiment_emotions.append(sentiment_labels[0]['label'])\n",
    "        go_sentiment_scores.append(sentiment_labels[0]['score'])\n",
    "    else:\n",
    "        #### none of the labels scored above the threshold\n",
    "        go_sentiment_emotions.append('None')\n",
    "        go_sentiment_scores.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding the output to the Pandas frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected the GO output in separate lists for each utterance. You can now add the output to the pandas frame as separate columns, assuming that the values correspond to the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Go_Sentiment</th>\n",
       "      <th>Go_SentimentScore</th>\n",
       "      <th>Go_Ekman</th>\n",
       "      <th>Go_EkmanScore</th>\n",
       "      <th>Go</th>\n",
       "      <th>GoScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.237066</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.287125</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.330824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.843814</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.843814</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.843814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.344749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.339241</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0.339241</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.585612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold Go_Sentiment  Go_SentimentScore  Go_Ekman  Go_EkmanScore  \\\n",
       "0        1  neutral    ambiguous           0.237066   neutral       0.287125   \n",
       "1        1  sadness     negative           0.843814   sadness       0.843814   \n",
       "2        1  neutral     negative           0.344749   sadness       0.344749   \n",
       "3        1  sadness     negative           0.107874   neutral       0.200429   \n",
       "4        1  neutral    ambiguous           0.339241  surprise       0.339241   \n",
       "\n",
       "          Go   GoScore  \n",
       "0  curiosity  0.330824  \n",
       "1    sadness  0.843814  \n",
       "2    sadness  0.344749  \n",
       "3    neutral  0.200429  \n",
       "4  curiosity  0.585612  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Go_Sentiment']=go_sentiment_emotions\n",
    "df['Go_SentimentScore']=go_sentiment_scores\n",
    "df['Go_Ekman']=go_ekman_emotions\n",
    "df['Go_EkmanScore']=go_ekman_scores\n",
    "df['Go']=go_emotions\n",
    "df['GoScore']=go_scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluation of the human response labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 10\n",
      "['sadness', 'neutral', 'neutral', 'neutral', 'sadness', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES\n",
    "human_response_prediction_labels = util.remove_eliza_labels(df, go_ekman_emotions)\n",
    "print(len(go_ekman_emotions), len(human_response_prediction_labels))\n",
    "print(human_response_prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Apply the BoW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Loading the BoW SVM classifier from MELD and TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO BUILD THE BOW SVM CLASSIFIER FROM MELD AND WASSA TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Applying and the classifier to the human part of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES TO CODE TO APPLY HERE COMES THE CODE TO APPLY THE CLASSIFIER TO THE UTTERANCES AND GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE OUTPUT TO THE PANDAS DATA FRAME AS WAS DONE FOR THE GO EMOTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Evaluation of the human response labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. [2 BONUS POINT] Sentiment classification and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP EKMAN TO SENTIMENT\n",
    "sentiment_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO MAP THE EKMAN TEST LABELS TO SENTIMENT TEST LABEL\n",
    "\n",
    "def ekman_to_sentiment (sentiment_map, test_labels):\n",
    "    human_sentiment_test_labels = []\n",
    "    return human_sentiment_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(human_test_labels)\n",
    "human_sentiment_test_labels = ekman_to_sentiment(sentiment_map, human_test_labels)\n",
    "print(human_sentiment_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Applying VADER for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO APPLY VADER TO THE UTTERANCES AND ADD THE OUTPUT TO THE PANDAS DATAFRAME\n",
    "vader_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE VADER SENTIMENT TO THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluating the GO_emotion sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SENTIMENT LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE FOR THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Evaluating the BoW-SVM emotions mapped to sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO MAP THE BOW EKMAN CODE TO SENTIMENT VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE BoW-SVM sentiment to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE PREDICTIONS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Training Bow-SVM with sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SEPARATE NOTEBOOK lab5.meld-tweet-bow-svm-sentiment-classifier.ipynb TO TRAIN A BOW SVM CLASSIFIER FOR SENTIMENT FROM MELD AND WASSA-TWEETS\n",
    "# SAVE THE CLASSIFIER TO DISK AND LOAD IT HERE\n",
    "\n",
    "# HERE COMES THE CODE TO LOAD A BOW SVM CLASSIFIER FOR SENTIMENT FROM MELD AND WASSA-TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO CLASSIFY THE CONVERSATION WITH SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE SENTIMENT TO THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE PREDICTIONS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO TO GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX FOR SENTIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving the dataframe will all the predictions to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE FINAL PANDAS FRAME TO A CSV FILE FOR YOUR SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
