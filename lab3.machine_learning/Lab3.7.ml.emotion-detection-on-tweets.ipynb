{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3.7 Testing classifiers on a different data set with tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set that we are going to use is from a NLP task on emotion detection that was organised in the *Wassa* workshop in 2017. The texts are tweets and therefore a different genre than the spoken utterances from the conversations in the MELD data set:\n",
    "\n",
    "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
    "\n",
    "We included the data set in the distribution of this lab and aggregated all the training data in a single file that we now can load using *Pandas*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the tweet data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              Tweet  Label  Score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...  anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...  anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...  anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...  anger  0.896"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = './data/wassa/training/all.train.tsv'\n",
    "dftweets_train = pd.read_csv(filepath, sep='\\t')\n",
    "dftweets_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3613 entries, 0 to 3612\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      3613 non-null   int64  \n",
      " 1   Tweet   3613 non-null   object \n",
      " 2   Label   3613 non-null   object \n",
      " 3   Score   3613 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 113.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dftweets_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this data set has 3613 tweets, labels and a score. Lets check the distribution of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftweets_train.Label.value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Test data\n",
    "filepath = './data/wassa/testing/all.test.tsv'\n",
    "dftweets_test = pd.read_csv(filepath, sep='\\t')\n",
    "dftweets_test.Label.value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this data set is more evenly distributed and there are no neutral tweets. Also lacking are *disgust* and *surprise*. Let's see what our classifier does on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extract the tweets and labels using a similar loop as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3613\n",
      "3613\n"
     ]
    }
   ],
   "source": [
    "tweet_train_instances=[]\n",
    "tweet_train_labels = []\n",
    "for tweet in dftweets_train['Tweet']:\n",
    "    ### We break the loop after 2000 instances \n",
    "    #if index==2000:\n",
    "    #    break\n",
    "    tweet_train_instances.append(tweet)\n",
    "\n",
    "\n",
    "for label in dftweets_train['Label']:\n",
    "    ### We break the loop after 2000 instances \n",
    "    #if index==2000:\n",
    "    #    break    ### we need to surround the next statements with 'try' and 'except' to catch cases \n",
    "    tweet_train_labels.append(label)\n",
    "\n",
    "print(len(tweet_train_instances))\n",
    "print(len(tweet_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142\n",
      "3142\n"
     ]
    }
   ],
   "source": [
    "tweet_test_instances=[]\n",
    "tweet_test_labels = []\n",
    "for tweet in dftweets_test['Tweet']:\n",
    "    ### We break the loop after 2000 instances \n",
    "    #if index==2000:\n",
    "    #    break\n",
    "    tweet_test_instances.append(tweet)\n",
    "\n",
    "\n",
    "for label in dftweets_test['Label']:\n",
    "    ### We break the loop after 2000 instances \n",
    "    #if index==2000:\n",
    "    #    break    ### we need to surround the next statements with 'try' and 'except' to catch cases \n",
    "    tweet_test_labels.append(label)\n",
    "\n",
    "print(len(tweet_test_instances))\n",
    "print(len(tweet_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Representing and classifying the tweets as averaged word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Representing the tweet training data using the same word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same functions that we used in the notebook *Lab3.6.ml.emotion-detection.embeddings.ipynb* to get averaged embeddings for the tweets. \n",
    "In order to use exactly the same function and to be able to re-use them again, we moved the exact function to a separate python file \"lab3_util.py\".\n",
    "\n",
    "We can now import this file as we do with other packages and apply it in this notebook but also in other code. This keeps our notebook readable and compact and makes sure we always use the same functions and do not accidently change them across notebooks.\n",
    "\n",
    "Note that the tweets have special tokens such as hashtags, emoticons. In so far these are not part of the embedding vocabulary, they will not be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab3_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to load the same word embedding model as we used before to get compatible word embeddings for this data. Choose whatever is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "# download the model and return as object ready for use\n",
    "wordembeddings=\"glove-twitter-25\"\n",
    "word_embedding_model = api.load(wordembeddings)\n",
    "num_features = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of words above the frequency threshold 1447\n",
      "Frequency threshold 4\n",
      "Shape of our matrix is: (3613, 25)\n",
      "Review 0 of 3613\n",
      "Review 1000 of 3613\n",
      "Review 2000 of 3613\n",
      "Review 3000 of 3613\n"
     ]
    }
   ],
   "source": [
    "#### We turn the word2vec wordindex into a set for efficiency\n",
    "index2word_set = set(word_embedding_model.wv.index2word)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    " #### We use two word list to keep track of the words that are also in the embedding model and words that are not\n",
    "\n",
    "known_words = []  # utterance words that are also in the embedding model\n",
    "unknown_words =[] # utterance words that are not in the mebedding model\n",
    "\n",
    "frequency_threshold=4\n",
    "keywords = util.getMostFrequentWords(frequency_threshold, tweet_train_instances)\n",
    "\n",
    "tweet_tokens = []\n",
    "for tweet in tweet_train_instances:\n",
    "    tweet_tokens.append(nltk.tokenize.word_tokenize(tweet))\n",
    "\n",
    "trainDataVecs, known_words, unknown_words = util.getAvgFeatureVecs(tweet_tokens, \n",
    "                                                                             keywords, \n",
    "                                                                             stop_words, \n",
    "                                                                             word_embedding_model, \n",
    "                                                                             index2word_set, \n",
    "                                                                             num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown word types 47\n",
      "Number of unknown word tokens: 870\n",
      "Unknown words counts\n",
      "Counter({'...': 275, '2': 59, 'live.ly': 54, '3': 38, '\\\\n': 29, 'ðŸ˜‚': 24, '4': 21, 'realdonaldtrump': 21, '..': 21, '\\\\n\\\\n': 18, 'bb18': 16, '1': 16, 'hillaryclinton': 16, '15': 14, '10': 13, 'ðŸ™„': 13, '5': 11, '6': 11, '2016': 10, \"y'all\": 10, 'ðŸ˜­': 10, '20': 10, 'ðŸ˜‚ðŸ˜‚': 9, '7': 9, 'ðŸ˜•': 8, '100': 8, 'â¤ï¸': 8, 'ðŸ˜¡': 7, 'w/': 7, '12': 7, '8': 7, '70': 7, 'charlotteprotest': 6, 'ðŸ˜©': 6, '3rd': 6, 'mhchat': 6, 'ðŸ˜¢': 6, 'ðŸ˜³': 6, 'wch2016': 6, 'thenicebot': 6, 'ðŸ¤—': 5, 'ðŸ™ƒ': 5, '17': 5, 'ðŸ˜‚ðŸ˜‚ðŸ˜‚': 5, '2day': 5, 'ðŸ˜…': 5, '48': 5})\n",
      "Proportion of unknown tokens 0.024041782960731756\n",
      "Number of known word types: 1205\n",
      "Number of known word tokens: 35317\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "if len(unknown_words)>0:\n",
    "    unknown_words_count = Counter(unknown_words)\n",
    "    print('Number of unknown word types',len(unknown_words_count))\n",
    "    print('Number of unknown word tokens:', len(unknown_words))\n",
    "    print('Unknown words counts')\n",
    "    print(unknown_words_count)\n",
    "    print('Proportion of unknown tokens', len(unknown_words)/(len(unknown_words)+len(known_words)))\n",
    "\n",
    "\n",
    "known_words_count = Counter(known_words)\n",
    "print('Number of known word types:',len(known_words_count))\n",
    "print('Number of known word tokens:', len(known_words))\n",
    "#print(known_words_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that emoticons are not in the vocabulary of the embedding model. Most words are however covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Representing the tweet test data through embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (3142, 25)\n",
      "Review 0 of 3142\n",
      "Review 1000 of 3142\n",
      "Review 2000 of 3142\n",
      "Review 3000 of 3142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweet_tokens = []\n",
    "for tweet in tweet_test_instances:\n",
    "    tweet_tokens.append(nltk.tokenize.word_tokenize(tweet))\n",
    "\n",
    "testDataVecs, known_words, unknown_words = util.getAvgFeatureVecs(tweet_tokens, \n",
    "                                                                             keywords, \n",
    "                                                                             stop_words, \n",
    "                                                                             word_embedding_model, \n",
    "                                                                             index2word_set, \n",
    "                                                                             num_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown word types 45\n",
      "Number of unknown word tokens: 748\n",
      "Unknown words counts\n",
      "Counter({'...': 301, '2': 67, 'ðŸ˜‚': 32, '3': 26, '1': 23, '\\\\n': 22, '4': 20, 'bb18': 17, '6': 16, '20': 14, '..': 13, '5': 13, 'realdonaldtrump': 12, 'hillaryclinton': 12, '10': 11, \"y'all\": 10, '15': 10, 'mhchat': 10, '7': 9, 'ðŸ˜‚ðŸ˜‚': 9, 'ðŸ™ƒ': 7, '100': 7, 'ðŸ˜©': 7, 'ðŸ˜­': 7, '\\\\n\\\\n': 7, '12': 7, '2016': 6, 'ðŸ˜…': 5, 'ðŸ™„': 5, 'ðŸ˜³': 5, 'w/': 4, '17': 4, '8': 3, 'ðŸ˜¡': 3, 'ðŸ˜¢': 3, 'â¤ï¸': 3, 'charlotteprotest': 3, 'ðŸ˜•': 3, '3rd': 3, 'ðŸ˜‚ðŸ˜‚ðŸ˜‚': 2, '48': 2, 'thenicebot': 2, 'live.ly': 1, 'wch2016': 1, '70': 1})\n",
      "Proportion of unknown tokens 0.02481340189086084\n",
      "Number of known word types: 1139\n",
      "Number of known word tokens: 29397\n"
     ]
    }
   ],
   "source": [
    "if len(unknown_words)>0:\n",
    "    unknown_words_count = Counter(unknown_words)\n",
    "    print('Number of unknown word types',len(unknown_words_count))\n",
    "    print('Number of unknown word tokens:', len(unknown_words))\n",
    "    print('Unknown words counts')\n",
    "    print(unknown_words_count)\n",
    "    print('Proportion of unknown tokens', len(unknown_words)/(len(unknown_words)+len(known_words)))\n",
    "\n",
    "\n",
    "known_words_count = Counter(known_words)\n",
    "print('Number of known word types:',len(known_words_count))\n",
    "print('Number of known word tokens:', len(known_words))\n",
    "#print(known_words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert the labels to the same numeric valus that we used before. We should use our LabelEncoder that we used before. However, we want the labels to have the same numeric values as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'fear', 'joy', 'sadness']\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# first we instantiate a label encode\n",
    "le = preprocessing.LabelEncoder()\n",
    "# we feed this encoder with the complete list of labels from our data\n",
    "labels = ['fear', 'anger', 'joy',  'sadness']\n",
    "le.fit(labels)\n",
    "print(list(le.classes_))\n",
    "tweet_train_classes = le.transform(tweet_train_labels)\n",
    "tweet_test_classes = le.transform(tweet_test_labels)\n",
    "\n",
    "print(list(tweet_train_classes[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first set of tweets are all expressing *anger* (idex '0') which makes sense given the way the data were concatenated from the separate files with tweets. Let's check tha last 10 tweets, which should score for *sadness*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(list(tweet_train_classes[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training and testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'sadness']\n",
      "Tweet Embeddings SVM LINEAR ----------------------------------------------------------------\n",
      "Word embedding model used glove-twitter-25\n",
      "Word frequency threshold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.4760077 0.3263158 0.3871975       760\n",
      "           1  0.4489281 0.7155779 0.5517241       995\n",
      "           2  0.5636605 0.5952381 0.5790191       714\n",
      "           3  0.4590747 0.1916790 0.2704403       673\n",
      "\n",
      "    accuracy                      0.4818587      3142\n",
      "   macro avg  0.4869178 0.4572027 0.4470952      3142\n",
      "weighted avg  0.4837238 0.4818587 0.4578808      3142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# We choose a Linear model\n",
    "svm_linear_clf = svm.LinearSVC(max_iter=2000)\n",
    "### we train the classifier through the *fit* function and by passing the training vectors and the training labels as paramters:\n",
    "svm_linear_clf.fit(trainDataVecs, tweet_train_classes)\n",
    "\n",
    "# Predicting the Test set results, find macro recall\n",
    "y_pred_svm_linear = svm_linear_clf.predict(testDataVecs)\n",
    "\n",
    "#### this report gives the results for the LINEAR classifier\n",
    "report = classification_report(tweet_test_classes,y_pred_svm_linear,digits = 7)\n",
    "print(le.classes_)\n",
    "print('Tweet Embeddings SVM LINEAR ----------------------------------------------------------------')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word frequency threshold', frequency_threshold)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we only have test results for the 4 classes because there are no tweet data for the other. The results are not that bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Testing the MELD classifiers on the tweets test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not trained and tested an emotion classifier on tweet data. What about the MELD classifiers that we have built? Can we load these and test them on the same test tweet data set?\n",
    "\n",
    "With embeddings this is easy because the representations are independent of the words but we need to use the same embedding model for both the training. So if we used the *glove_twitter* embeddings for MELD with 25 dimensions, we have to do the same for the tweet test data.\n",
    "\n",
    "For the BoW classifiers, we need to use CountVectorizer and the *transform_fit* function to model the test data accordingly.\n",
    "\n",
    "If you saved the MELD models using the previous notebook, you can load the models now again. Otherwise, you need to rebuilt them, save them and next load them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Loading the MELD classifier for embedding representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename_classifier = './models/svm_linear_clf_embeddings.sav'\n",
    "\n",
    "# load the classifier and the vectorizer from disk\n",
    "svm_linear_clf = pickle.load(open(filename_classifier, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the vector representations for MELD and the test tweets were creating using the same function and through the same mebdding model we can now use it directly to classify the tweet test data we just created in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'sadness']\n",
      "SVM NONLINEAR EMBEDDINGS ----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.4561404 0.0342105 0.0636475       760\n",
      "           1  0.0000000 0.0000000 0.0000000       995\n",
      "           2  0.0000000 0.0000000 0.0000000       714\n",
      "           3  0.2063492 0.2511144 0.2265416       673\n",
      "           4  0.0000000 0.0000000 0.0000000         0\n",
      "           5  0.0000000 0.0000000 0.0000000         0\n",
      "           6  0.0000000 0.0000000 0.0000000         0\n",
      "\n",
      "    accuracy                      0.0620624      3142\n",
      "   macro avg  0.0946414 0.0407607 0.0414556      3142\n",
      "weighted avg  0.1545320 0.0620624 0.0639193      3142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# have classifier make a prediction\n",
    "tweet_pred_linear_embeddings = svm_linear_clf.predict(testDataVecs)\n",
    "report = classification_report(tweet_test_classes,tweet_pred_linear_embeddings,digits = 7)\n",
    "print(le.classes_)\n",
    "print('SVM NONLINEAR EMBEDDINGS ----------------------------------------------------------------')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the tweets data is different from MELD, we see that there is no support for *disgust*, *neutral*, and *surprise*. These are not in the data set.\n",
    "There is data for *fear* and *joy* but the results are bad with zero recall and zero precision. This clearly shows you cannot easily deploy a classifier to other types of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Representing and classifying the tweets as a bag-of-words vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Representing the tweets as BoW vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to represent the test tweets according to our BoW vector representation derived from the MELD data, we need to load the *utterance_vec* file that we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the classifier and the vectorizer from disk\n",
    "filename_vectorizer = './models/utterance_vec.sav'\n",
    "loaded_vectorizer = pickle.load(open(filename_vectorizer, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the transform function to the tokenized tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3142, 1217)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#utterance_tfidf = tfidf_transformer.fit_transform(utterance_counts)\n",
    "tweet_vectors = loaded_vectorizer.transform(tweet_test_instances)\n",
    "tweet_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the matrix has vectors of the same size as before for the BoW token vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the classifier and make the prediction in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier on disk\n",
    "filename_classifier = './models/svm_linear_clf_bow.sav'\n",
    "\n",
    "loaded_bow_classifier = pickle.load(open(filename_classifier, 'rb'))\n",
    "\n",
    "pred_from_loaded_bow_classifier = loaded_bow_classifier.predict(tweet_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'sadness']\n",
      "SVM LINEAR BOW ----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.3082707 0.1618421 0.2122519       760\n",
      "           1  0.3116883 0.0482412 0.0835509       995\n",
      "           2  0.1612903 0.0070028 0.0134228       714\n",
      "           3  0.2046385 0.2228826 0.2133713       673\n",
      "           4  0.0000000 0.0000000 0.0000000         0\n",
      "           5  0.0000000 0.0000000 0.0000000         0\n",
      "           6  0.0000000 0.0000000 0.0000000         0\n",
      "\n",
      "    accuracy                      0.1037556      3142\n",
      "   macro avg  0.1408411 0.0628527 0.0746567      3142\n",
      "weighted avg  0.2537551 0.1037556 0.1265523      3142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(tweet_test_classes,pred_from_loaded_bow_classifier,digits = 7)\n",
    "print(le.classes_)\n",
    "print('SVM LINEAR BOW ----------------------------------------------------------------')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the BoW SVM classifier trained from MELD again performs slightly better than the MELD embeddings SVM classifier. We now do get a score for *fear* and *joy*. Nevertheless, the scores are very low compared to the classifier trained on the tweet training data, which confirms that domain and genre bias of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
